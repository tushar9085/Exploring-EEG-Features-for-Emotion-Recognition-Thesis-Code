{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 4, 32, 168)\n",
      "(1280, 4)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "\n",
    "def calculate_time_domain_features(segment):\n",
    "    mean_value = np.mean(segment)\n",
    "    std_dev = np.std(segment)\n",
    "    var = np.var(segment, ddof=1)\n",
    "    kurt = kurtosis(segment)\n",
    "    #max_value = np.max(segment)\n",
    "    return mean_value, std_dev, var, kurt\n",
    "\n",
    "def load_data(data_dir): \n",
    "    fs = 128  # Adjusted to match DEAP dataset's sampling frequency\n",
    "    fStart = [4, 8, 14, 31]\n",
    "    fEnd = [7, 13, 30, 45]\n",
    "    selected_channels = range(32)  # Adjusted to include only the first 32 channels\n",
    "    seconds_to_exclude = 10\n",
    "\n",
    "    datasets_X, datasets_y = [], []\n",
    "\n",
    "    for filename_data in os.listdir(data_dir):\n",
    "        if filename_data.endswith(\".mat\"):\n",
    "            # Load data and labels\n",
    "            mat_data = loadmat(os.path.join(data_dir, filename_data))\n",
    "            data = mat_data['data']  # Shape: (40, 40, 8064)\n",
    "            labels = mat_data['labels']  # Shape: (40, 4)\n",
    "\n",
    "            for trial_index in range(data.shape[0]):\n",
    "                dataset_X = []\n",
    "                trial_data = data[trial_index, selected_channels, :]  # Selecting only the first 32 channels\n",
    "\n",
    "                # Exclude the first and last 10 seconds\n",
    "                start_index = seconds_to_exclude * fs\n",
    "                end_index = -seconds_to_exclude * fs\n",
    "\n",
    "                trial_data = trial_data[:, start_index:end_index]\n",
    "\n",
    "                for band_index, band in enumerate(fStart):\n",
    "                    b, a = signal.butter(4, [fStart[band_index]/fs, fEnd[band_index]/fs], 'bandpass')\n",
    "                    filtered_data = signal.filtfilt(b, a, trial_data)\n",
    "                    features = []\n",
    "\n",
    "                    for lead in selected_channels:\n",
    "                        feature = []\n",
    "                        for de_index in range(0, filtered_data.shape[1] - fs, fs):\n",
    "                            data_segment = filtered_data[lead, de_index: de_index + fs]\n",
    "                            mean_value, std_dev, var, kurt = calculate_time_domain_features(data_segment)\n",
    "                            # Append features to the list\n",
    "                            feature.append([mean_value, std_dev, var, kurt])\n",
    "\n",
    "                        features.append(feature)\n",
    "\n",
    "                    features = np.array(features)\n",
    "                    dataset_X.append(features)\n",
    "\n",
    "                dataset_X = np.array(dataset_X)\n",
    "                dataset_X = dataset_X.reshape((dataset_X.shape[0], dataset_X.shape[1], -1))\n",
    "\n",
    "                datasets_X.append(dataset_X)\n",
    "                datasets_y.append(labels[trial_index])\n",
    "\n",
    "    datasets_X, datasets_y = np.array(datasets_X), np.array(datasets_y)\n",
    "\n",
    "    return datasets_X, datasets_y\n",
    "\n",
    "data_dir = \"E:/STUDY/Publications/Thesis/Brain Emotion Detection/Dataset/DEAP/data_preprocessed_matlab/\"\n",
    "\n",
    "datasets_X, datasets_y = load_data(data_dir)\n",
    "print(datasets_X.shape)\n",
    "print(datasets_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "# Reshape datasets_X to (40, 4, 32, 42, 4)\n",
    "#reshaped_datasets_X = datasets_X.reshape((40, 4, 32, 42, 4))\n",
    "\n",
    "# Verify the new shape\n",
    "#print(reshaped_datasets_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 32, 168, 4)\n"
     ]
    }
   ],
   "source": [
    "new_datasets_X = np.copy(datasets_X)\n",
    "new_datasets_X = np.transpose(new_datasets_X, (0, 2, 3, 1))\n",
    "print(new_datasets_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('DEAP_Time_Domain_X.npy', new_datasets_X)\n",
    "np.save('DEAP_Time_Domain_y.npy', datasets_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_code_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
